{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOE SKEW analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "if  not os.path.abspath('./') in sys.path:\n",
    "    sys.path.append(os.path.abspath('./'))\n",
    "if  not os.path.abspath('../') in sys.path:\n",
    "    sys.path.append(os.path.abspath('../'))\n",
    "from volgrid import dgrid\n",
    "from volgrid import create_voltables as cvt\n",
    "import dash_core_components as dcc\n",
    "import traceback\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from plotly.offline import  init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pandas_datareader.data as pdr\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "#  do rest of imports\n",
    "import dash\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "import yfinance as yf\n",
    "import pathlib\n",
    "import pg_pandas as pg\n",
    "from dateutil.relativedelta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some interest rate and calendar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "TIMEZONE = 'US/Eastern'\n",
    "\n",
    "def get_rate_df(num_months_for_rate=1,start_datetime=None,end_datetime=None):\n",
    "    # see if you can get Libor from the FRED API\n",
    "    if start_datetime is None:\n",
    "        n = datetime.datetime.now() - 252*bday_us #datetime.timedelta(7)\n",
    "    else:\n",
    "        if type(start_datetime)==int:\n",
    "            sdt = start_datetime\n",
    "            n = datetime.datetime(int(str(sdt)[0:4]),int(str(sdt)[4:6]), int(str(sdt)[6:8]))\n",
    "        else:\n",
    "            n = start_datetime \n",
    "    y = n.year\n",
    "    m = n.month\n",
    "    d = n.day\n",
    "    beg = '%04d-%02d-%02d' %(y,m,d)\n",
    "    ed = end_datetime if end_datetime is not None else (datetime.datetime.now() - datetime.timedelta(1))\n",
    "    if type(ed)==int:\n",
    "        ed = datetime.datetime(int(str(ed)[0:4]), int(str(ed)[4:6]), int(str(ed)[6:8]))\n",
    "    y = ed.year\n",
    "    m = ed.month\n",
    "    d = ed.day\n",
    "    eds = '%04d-%02d-%02d' %(y,m,d)\n",
    "    fred_libor_file = f'USD{num_months_for_rate}MTD156N'\n",
    "    df = pdr.DataReader(fred_libor_file, \"fred\", f'{beg}', f'{eds}')\n",
    "    if len(df)<1:\n",
    "        raise ValueError(f'FRED calendar of {fred_libor_file} does not contain dates {beg} through {eds}')\n",
    "    df['fixed_rate'] = df[f'USD{num_months_for_rate}MTD156N'].astype(float)/100\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df['date_yyyymmdd'] = [int(d.year*100*100) + int(d.month*100) + int(d.day) for d in df.index]\n",
    "    df.index = range(len(df))\n",
    "    df['prate'] = df.shift(1).fixed_rate\n",
    "    df['fixed_rate'] = df.apply(lambda r:r.prate if r.fixed_rate !=r.fixed_rate else r.fixed_rate,axis=1)\n",
    "    return df[['date_yyyymmdd','fixed_rate']]\n",
    "\n",
    "\n",
    "def get_rate(num_months_for_rate=1,rate_datetime=None):\n",
    "    # see if you can get Libor from the FRED API\n",
    "    if rate_datetime is None:\n",
    "        n = datetime.datetime.now() - 7*bday_us #datetime.timedelta(7)\n",
    "    else:\n",
    "        n = rate_datetime #- datetime.timedelta(14)\n",
    "    y = n.year\n",
    "    m = n.month\n",
    "    d = n.day\n",
    "    beg = '%04d-%02d-%02d' %(y,m,d)\n",
    "#     ed = n  + datetime.timedelta(1)\n",
    "    ed = datetime.datetime.now()\n",
    "    y = ed.year\n",
    "    m = ed.month\n",
    "    d = ed.day\n",
    "    eds = '%04d-%02d-%02d' %(y,m,d)\n",
    "    fred_libor_file = f'USD{num_months_for_rate}MTD156N'\n",
    "    df = pdr.DataReader(fred_libor_file, \"fred\", f'{beg}', f'{eds}')\n",
    "    if len(df)<1:\n",
    "        raise ValueError(f'FRED calendar of {fred_libor_file} does not contain dates {beg} through {eds}')\n",
    "#     fixed_rate = float(df.iloc[len(df)-1][f'USD{num_months_for_rate}MTD156N'])/100\n",
    "    fixed_rate = float(df.iloc[-1][f'USD{num_months_for_rate}MTD156N'])/100\n",
    "    return fixed_rate\n",
    "\n",
    "def get_nth_weekday(year,month,target_weekday,nth_occurrence):\n",
    "    '''\n",
    "    weekday is the term that assigns numbers from 0 to 6 to the days of the weeks.\n",
    "    weekday 0 = monday\n",
    "    '''\n",
    "    # get dayofweeks of year,month,1\n",
    "    weekday_01 = datetime.datetime(year,month,1).weekday()\n",
    "    if weekday_01 <= target_weekday:\n",
    "        day_of_month_of_first_occurence = target_weekday - weekday_01\n",
    "        day_of_month_of_nth_occurence = day_of_month_of_first_occurence + 1 + (nth_occurrence - 1) * 7\n",
    "    else:\n",
    "        day_of_month_of_nth_occurence = target_weekday - weekday_01 + 1 + (nth_occurrence) * 7 \n",
    "    return datetime.datetime(year,month,day_of_month_of_nth_occurence)\n",
    "\n",
    "\n",
    "MONTH_CODES = 'FGHJKMNQUVXZ'\n",
    "DICT_MONTH_CODE = {MONTH_CODES[i]:i+1 for i in range(len(MONTH_CODES))}\n",
    "\n",
    "\n",
    "def get_ES_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    return get_nth_weekday(year,month,4,3)\n",
    "\n",
    "def get_E6_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    next_month = DICT_MONTH_CODE[monthcode_yy[0]] + 1\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    if next_month>12:\n",
    "        next_month = 1\n",
    "        year += 1\n",
    "    return datetime.datetime(year,next_month,1) - 7*bday_us\n",
    "\n",
    "def get_CL_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    month = month -1\n",
    "    if month<1:\n",
    "        month = 12\n",
    "        year = year - 1\n",
    "    return datetime.datetime(year,month,26) - 7*bday_us\n",
    "\n",
    "def get_NG_expiry(symbol):\n",
    "    monthcode_yy = symbol[2:]\n",
    "    month = DICT_MONTH_CODE[monthcode_yy[0]]\n",
    "    year = 2000 + int(monthcode_yy[1:])\n",
    "    return datetime.datetime(year,month,1) - 4*bday_us\n",
    "\n",
    "DICT_PRODUCT = {\n",
    "    'E6':get_E6_expiry,\n",
    "    'ES':get_ES_expiry,\n",
    "    'CL':get_CL_expiry,\n",
    "    'NG':get_NG_expiry,\n",
    "}\n",
    "\n",
    "    \n",
    "def get_expiry(symbol):\n",
    "    product = symbol[:2]\n",
    "    f = DICT_PRODUCT[product]\n",
    "    return f(symbol)\n",
    "\n",
    "\n",
    "def dt_from_yyyymmdd(yyyymmdd,hour=0,minute=0,timezone=TIMEZONE):\n",
    "    y = int(str(yyyymmdd)[0:4])\n",
    "    m = int(str(yyyymmdd)[4:6])\n",
    "    d = int(str(yyyymmdd)[6:8])  \n",
    "    return datetime.datetime(y,m,d,hour,minute,tzinfo=pytz.timezone(timezone))\n",
    "\n",
    "def yyyymmdd_from_dt(dt):\n",
    "    y = int(dt.year)\n",
    "    m = int(dt.month)\n",
    "    d = int(dt.day)\n",
    "    return y*100*100 + m*100 + d\n",
    "\n",
    "def get_dte_pct(trade_yyyymmdd,expiry_yyyymmdd):\n",
    "    dt_td = dt_from_yyyymmdd(trade_yyyymmdd)\n",
    "    dt_xp = dt_from_yyyymmdd(expiry_yyyymmdd)\n",
    "    return ((dt_xp - dt_td).days + 1)/365\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dates vs last records in db for CL and ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg.PgPandas??\n",
    "pga = pg.PgPandas(dburl='127.0.0.1',username='',password='',databasename='sec_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "syms = ['NG'+m+yy for m in 'FGHJKMNQUVXZ' for yy in ['15','16','17','18','19']]\n",
    "for s in syms:\n",
    "    ge = str(get_expiry(s))\n",
    "    exp1 = int(ge[0:4])*100*100 + int(ge[5:7])*100 + int(ge[8:10])\n",
    "    \n",
    "    sql = f'''\n",
    "    select max(ot.settle_date) from sec_schema.options_table ot\n",
    "    where ot.symbol='{s}' \n",
    "    ;\n",
    "    '''\n",
    "    df_options = pga.get_sql(sql)\n",
    "    exp2 = df_options.iloc[0]['max']\n",
    "    print(s,exp1,exp2,exp1==exp2)\n",
    "    #assert(exp1==exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rate(1)#,rate_datetime=datetime.datetime(2020,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdf = get_rate_df(1,datetime.datetime(2018,8,1),datetime.datetime(2018,8,31))\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paremeters to calculate SPX based SKEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKEW_TICKER = '^SPX' # yahoo symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skew = pd.read_csv('https://www.cboe.com/publish/scheduledtask/mktdata/datahouse/skewdailyprices.csv',header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_skew['date_split'] = df_skew.Date.apply(lambda s:s.split('/'))\n",
    "df_skew['yyyymmdd'] = df_skew.date_split.apply(lambda s:int(s[2])*100*100 + int(s[0])*100 + int(s[1]))\n",
    "df_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_closest_expiry_to_dt(dt=None,options_ticker=SKEW_TICKER):\n",
    "    nn = dt\n",
    "    if nn is None:\n",
    "        nn = datetime.datetime.now()\n",
    "    spx = yf.Ticker(options_ticker)\n",
    "    dt_nth_weekday = get_nth_weekday(int(nn.year),int(nn.month),4,3)\n",
    "    spx_expirys = [datetime.datetime(int(s[0:4]),int(s[5:7]),int(s[8:10])) for s in spx.options]\n",
    "    diffs = [abs((se - dt_nth_weekday).days) for se in spx_expirys]\n",
    "    index_of_closes_expiry = diffs.index(min(diffs))\n",
    "    ret_exp = spx_expirys[index_of_closes_expiry]\n",
    "    return ret_exp\n",
    "def get_current_spx_3rd_friday_exp():\n",
    "    nn = datetime.datetime.now()\n",
    "    exp1 = get_closest_expiry_to_dt(dt=nn)\n",
    "    dt_2nd_month = nn + relativedelta(months=+1)\n",
    "    exp2 = get_closest_expiry_to_dt(dt=dt_2nd_month)\n",
    "    dt_3rd_month = dt_2nd_month + relativedelta(months=+1)\n",
    "    exp3 = get_closest_expiry_to_dt(dt=dt_3rd_month)    \n",
    "    if (exp1 - nn).days < 10:\n",
    "        return (exp2,exp3)\n",
    "    return (exp1,exp2)\n",
    "get_current_spx_3rd_friday_exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parmeters related to fetching current values of SPX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_BID = .1 # minimum bid value when screening options\n",
    "DELTA_K = 5 # strike difference between most of the options that get used to calculate SKEW\n",
    "TRADE_DATE = 20191224\n",
    "EXP_NEAR_YYYYMMDD = 20200116\n",
    "EXP_FAR_YYYYMMDD = 20200220\n",
    "INTEREST_RATE = (get_rate(1) + get_rate(2))/2 # calculate at run time ( this will be the average of the 1 month and 2 month libor rates from FRED)\n",
    "\n",
    "OUTPUT_COLS = ['contractSymbol','strike','mid','dte_pct','ert',\n",
    "                'forward_price','deltak','p1','p2','p3','e1','e2','e3']\n",
    "\n",
    "DICT_THRESHOLD_BIDS = {'ES':1,'CL':.02,'CB':.02,'NG':.002}\n",
    "DICT_DELTAK = {'ES':5,'CL':.5,'CB':.5,'NG':.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = str(EXP_FAR_YYYYMMDD)\n",
    "dd = f'{ed[0:4]}-{ed[4:6]}-{ed[6:8]}'\n",
    "c = yf.Ticker('^SPX')\n",
    "df_t = c.option_chain(dd)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tp = df_t.puts[(df_t.puts.contractSymbol.str.slice(0,4)=='SPX2')]\n",
    "df_tp[df_tp.strike>=3220.0].iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tc = df_t.calls[(df_t.calls.bid>.1) & (df_t.calls.contractSymbol.str.slice(0,4)=='SPX2')]\n",
    "df_tc[~df_tc.inTheMoney].iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_valid_series_from_yfinance(trade_date_yyyymmdd,expiry_yyyymmdd,ticker=SKEW_TICKER,threshold_bid=THRESHOLD_BID,interest_rate=None,deltak=DELTA_K):\n",
    "#     # ****** Step 01: create interest rate to use if necessary\n",
    "    assert(interest_rate is not None)\n",
    "    ir = interest_rate\n",
    "#     if ir is None:\n",
    "#         ir  = (get_rate(1) + get_rate(2))/2\n",
    "    # ******  Step 02:  get yfinance contract, and options series\n",
    "    contract = yf.Ticker(ticker)\n",
    "    # reformat expiry_yyyymmdd into something like 2019-12-20\n",
    "    ed = str(expiry_yyyymmdd)\n",
    "    date_string = f'{ed[0:4]}-{ed[4:6]}-{ed[6:8]}'\n",
    "    # get the options chain from yahoo finance\n",
    "    df_opt = contract.option_chain(date_string)\n",
    "\n",
    "    # ****** Step 03: figure out forward price\n",
    "    df_spx_p = df_opt.puts[(df_opt.puts.bid>threshold_bid) & (df_opt.puts.contractSymbol.str.slice(0,4)=='SPX2')].copy()\n",
    "    df_spx_p['cp'] = 'p'\n",
    "    \n",
    "    # ******  Step 03:  extract out of the money puts\n",
    "    df_spx_p = df_spx_p[~df_spx_p.inTheMoney]\n",
    "    df_spx_p = df_spx_p.sort_values('strike')\n",
    "    df_spx_p.index = range(len(df_spx_p))\n",
    "\n",
    "    # ******  Step 04: extract out the ATM and the out of the money calls\n",
    "    df_spx_c = df_opt.calls[(df_opt.calls.bid>threshold_bid) & (df_opt.calls.contractSymbol.str.slice(0,4)=='SPX2')].copy()\n",
    "    return df_spx_c\n",
    "    if len(df_spx_c) < 1:\n",
    "        # if no bids, use strikes up to 10% out of the money\n",
    "        last_put_strike = df_spx_p.iloc[-1].strike\n",
    "        last_call_strike = round(last_put_strike*1.1,0)\n",
    "        df_spx_c = df_opt.calls[(df_opt.calls.strike<=last_call_strike) & (df_opt.calls.contractSymbol.str.slice(0,4)=='SPX2')].copy()\n",
    "        return df_spx_c\n",
    "    df_spx_c['cp'] = 'c'\n",
    "    df_spx_c = df_spx_c[~df_spx_c.inTheMoney]\n",
    "    df_spx_c = df_spx_c.sort_values('strike')\n",
    "    df_spx_c.index = range(len(df_spx_c))\n",
    "    first_call_strike = df_spx_c.iloc[0].strike\n",
    "    # save the lowest_itm_put for later calc of forward price\n",
    "    call_strikes = df_spx_c.strike.values\n",
    "    lowest_itm_put = df_spx_p[(df_spx_p.strike>=first_call_strike) & df_spx_p.strike.isin(call_strikes)].iloc[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    # ******  Step 05: merge puts and alls into one dataframe\n",
    "    df_ret = df_spx_p.copy()\n",
    "    df_ret = df_ret.append(df_spx_c)\n",
    "    df_ret = df_ret.sort_values(['cp','strike'])\n",
    "    df_ret.index = range(len(df_ret))\n",
    "    df_ret['expiry_yyyymmdd'] = expiry_yyyymmdd\n",
    "    df_ret['trade_date_yyyymmdd'] = trade_date_yyyymmdd\n",
    "        \n",
    "    # ******  Step 06: Add mid price, expiry, dte_pct, ert, forward price     \n",
    "    df_ret['mid'] = (df_ret.bid + df_ret.ask)/2\n",
    "    dte_pct = get_dte_pct(trade_date_yyyymmdd,expiry_yyyymmdd)\n",
    "    df_ret['dte_pct'] = dte_pct\n",
    "    ert = np.exp(dte_pct * ir)\n",
    "    df_ret['ert'] = ert\n",
    "    # find forward price by using the lowest strike call in df_ret \n",
    "    #     (what the SKEW whitepaper calls the At The Money option)\n",
    "    # get ATM call midpoint\n",
    "    atm_strike = lowest_itm_put.strike \n",
    "    \n",
    "    atm_call = df_ret[(df_ret.strike==atm_strike) & (df_ret.cp=='c')].iloc[0]\n",
    "    atm_call_price = (atm_call.bid + atm_call.ask) / 2 \n",
    "    atm_put = lowest_itm_put\n",
    "    atm_put_price = (atm_put.bid + atm_put.ask) / 2 \n",
    "    forward_price = ert*(atm_call_price - atm_put_price) + atm_strike\n",
    "    df_ret['forward_price'] = forward_price\n",
    "    df_ret['k_over_fp'] = df_ret.strike / forward_price\n",
    "    df_ret['deltak'] = deltak\n",
    "    # create p1 unit values\n",
    "    df_ret['p1']= df_ret.apply(lambda r: r.deltak / r.strike**2 * r.mid,axis=1)\n",
    "    df_ret['p2'] = df_ret.apply(lambda r: 2 * r.p1 *(1-np.log(r.k_over_fp)),axis=1)\n",
    "    df_ret['p3'] = df_ret.apply(lambda r: 3 * r.p1 * (2*np.log(r.k_over_fp) - np.log(r.k_over_fp)**2),axis=1)\n",
    "    e1 = -(1+np.log(forward_price/atm_strike) - forward_price/atm_strike)\n",
    "    e2 = 2 * np.log(atm_strike/forward_price) * (forward_price/atm_strike - 1) + 1/2 * np.log(atm_strike/forward_price)**2\n",
    "    e3 = 3 * np.log(atm_strike/forward_price)**2 * (1/3 * np.log(atm_strike/forward_price) - 1 + forward_price/atm_strike)\n",
    "    df_ret['e1'] = e1\n",
    "    df_ret['e2'] = e2\n",
    "    df_ret['e3'] = e3\n",
    "    return df_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1,exp2 = get_current_spx_3rd_friday_exp()\n",
    "td = datetime.datetime.now() - 7*bday_us\n",
    "exp1_yyyymmdd = yyyymmdd_from_dt(exp1)\n",
    "exp2_yyyymmdd = yyyymmdd_from_dt(exp2)\n",
    "\n",
    "ir_now = (get_rate(1,td) + get_rate(2,td))/2 # calculate at run time ( this will be the average of the 1 month and 2 month libor rates from FRED)\n",
    "\n",
    "df_series_near = get_valid_series_from_yfinance(td,exp1_yyyymmdd,interest_rate=ir_now)\n",
    "df_series_far = get_valid_series_from_yfinance(td,exp2_yyyymmdd,interest_rate=ir_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_series_far[df_series_far.cp=='c'].iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_series_near[df_series_near.cp=='p'].iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum up p1's p2's and p3's and computer e1, e2, and e3', and create SKEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew(df_series):\n",
    "    e1 = df_series.iloc[0].e1\n",
    "    e2 = df_series.iloc[0].e2\n",
    "    e3 = df_series.iloc[0].e3\n",
    "    ert = df_series.iloc[0].ert\n",
    "    p1 = ert * -1 * df_series.p1.sum() + e1\n",
    "    p2 = ert * df_series.p2.sum() + e2\n",
    "    p3 = ert * df_series.p3.sum() + e3\n",
    "    S_ =  (p3 - 3*p1*p2 + 2*p1**3) / (p2 - p1**2)**(3/2)\n",
    "    SKEW = 100 - 10*S_\n",
    "    return SKEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tnear = df_series_near.iloc[0].dte_pct\n",
    "# Tfar = df_series_far.iloc[0].dte_pct\n",
    "# T30 = 30/365\n",
    "# w = (Tfar-T30)/(Tfar-Tnear)\n",
    "# skew_near = create_skew(df_series_near)\n",
    "# skew_far = create_skew(df_series_far)\n",
    "# final_skew = w*skew_near + (1-w) * skew_far\n",
    "# print(final_skew,skew_near,skew_far,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now do multiple days from Oct 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_series_from_csv_file_df(df,threshold_bid=THRESHOLD_BID,interest_rate=INTEREST_RATE,deltak=DELTA_K):\n",
    "    '''\n",
    "    df: a DataFrame containing options settlements for a single day, and a single expiry\n",
    "    '''\n",
    "    # ****** Step 01: create interest rate to use if necessary\n",
    "    ir = interest_rate\n",
    "#     if ir is None:\n",
    "#         ir  = (get_rate(1) + get_rate(2))/2\n",
    "    \n",
    "    df_ret = df.copy()\n",
    "    trade_date_yyyymmdd = df_ret.trade_date_yyyymmdd.iloc[0]\n",
    "    expiry_yyyymmdd = df_ret.expiry_yyyymmdd.iloc[0]\n",
    "    assert(len(df_ret.expiry_yyyymmdd.unique())==1)\n",
    "    # ******  Step 02: Add mid price, expiry, dte_pct, ert, forward price     \n",
    "    df_ret['mid'] = (df_ret.bid + df_ret.ask)/2\n",
    "    dte_pct = get_dte_pct(trade_date_yyyymmdd,expiry_yyyymmdd)\n",
    "    df_ret['dte_pct'] = dte_pct\n",
    "    ert = np.exp(dte_pct * ir)\n",
    "    df_ret['ert'] = ert\n",
    "    lowest_atm_call = df_ret[(df_ret.underlying_last<df_ret.strike) & (df_ret.cp=='c')].sort_values('strike').iloc[0]\n",
    "    atm_call_price = lowest_atm_call.mid\n",
    "    atm_strike = lowest_atm_call.strike\n",
    "    atm_put_price = df_ret[(df_ret.strike==atm_strike) & (df_ret.cp=='p')].iloc[0].mid\n",
    "    forward_price = ert*(atm_call_price - atm_put_price) + atm_strike\n",
    "    \n",
    "    # ******  Step 03: Limit options to out of the money puts, the ATM call and out of the money calls\n",
    "    df_ret_c = df_ret[(df_ret.cp=='c') & (df_ret.strike>=atm_strike)]\n",
    "    df_ret_p = df_ret[(df_ret.cp=='p') & (df_ret.strike<atm_strike)]\n",
    "    df_ret = df_ret_c.append(df_ret_p).sort_values(['cp','strike'])\n",
    "    # ******  Step 04: make sure options have minimum bid\n",
    "    df_ret = df_ret[df_ret.bid>threshold_bid]\n",
    "    \n",
    "    \n",
    "    df_ret['forward_price'] = forward_price\n",
    "    df_ret['k_over_fp'] = df_ret.strike / forward_price\n",
    "    df_ret['deltak'] = deltak\n",
    "    # create p1 unit values\n",
    "    df_ret['p1']= df_ret.apply(lambda r: r.deltak / r.strike**2 * r.mid,axis=1)\n",
    "    df_ret['p2'] = df_ret.apply(lambda r: 2 * r.p1 *(1-np.log(r.k_over_fp)),axis=1)\n",
    "    df_ret['p3'] = df_ret.apply(lambda r: 3 * r.p1 * (2*np.log(r.k_over_fp) - np.log(r.k_over_fp)**2),axis=1)\n",
    "    e1 = -(1+np.log(forward_price/atm_strike) - forward_price/atm_strike)\n",
    "    e2 = 2 * np.log(atm_strike/forward_price) * (forward_price/atm_strike - 1) + 1/2 * np.log(atm_strike/forward_price)**2\n",
    "    e3 = 3 * np.log(atm_strike/forward_price)**2 * (1/3 * np.log(atm_strike/forward_price) - 1 + forward_price/atm_strike)\n",
    "    df_ret['e1'] = e1\n",
    "    df_ret['e2'] = e2\n",
    "    df_ret['e3'] = e3\n",
    "\n",
    "    return df_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_to_yyyymmdd(yyyymmdd,days_to_add):\n",
    "    s = str(yyyymmdd)\n",
    "    y = int(s[0:4])\n",
    "    m = int(s[4:6])\n",
    "    d = int(s[6:8])\n",
    "    dt = datetime.datetime(y,m,d) + datetime.timedelta(days_to_add)\n",
    "    ret = int(dt.year)*100*100 + int(dt.month)*100 + int(dt.day)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home =  pathlib.Path.home()\n",
    "df_spx_oct_2015= pd.read_csv(f'{home}/downloads/spx_20151001_to_20151030.csv')\n",
    "df_spx_oct_2015 = df_spx_oct_2015[df_spx_oct_2015.underlying=='SPX']\n",
    "df_spx_oct_2015['cp'] = df_spx_oct_2015['type'].apply(lambda v:v[0])\n",
    "df_spx_oct_2015['trade_date_yyyymmdd'] = df_spx_oct_2015.quotedate.apply(lambda s:s.split('/'))\n",
    "df_spx_oct_2015['trade_date_yyyymmdd'] = df_spx_oct_2015.trade_date_yyyymmdd.apply(lambda s:(2000 + int(s[2]))*100*100 + int(s[0])*100 + int(s[1]))\n",
    "df_spx_oct_2015['expiry_yyyymmdd'] = df_spx_oct_2015.expiration.apply(lambda s:s.split('/'))\n",
    "df_spx_oct_2015['expiry_yyyymmdd'] = df_spx_oct_2015.expiry_yyyymmdd.apply(lambda s:(2000 + int(s[2]))*100*100 + int(s[0])*100 + int(s[1]))\n",
    "\n",
    "df_spx_oct_2015.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx_oct_2015[df_spx_oct_2015.trade_date_yyyymmdd==20151001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique quotedate's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_dates_yyyymmdd = df_spx_oct_2015.trade_date_yyyymmdd.unique()\n",
    "dict_df_exp_pair = {}\n",
    "for d in trade_dates_yyyymmdd:\n",
    "    first_expiry_cutoff = add_days_to_yyyymmdd(d,10)\n",
    "    df_spx_1 = df_spx_oct_2015[(df_spx_oct_2015.trade_date_yyyymmdd==d) & (df_spx_oct_2015.expiry_yyyymmdd>first_expiry_cutoff)]\n",
    "    first_2_expiries = df_spx_1.expiry_yyyymmdd.unique()[:2]\n",
    "    df_spx_exp1 = df_spx_1[df_spx_1.expiry_yyyymmdd==first_2_expiries[0]]\n",
    "    df_spx_exp1_with_all_fields = get_valid_series_from_csv_file_df(df_spx_exp1)\n",
    "    df_spx_exp2 = df_spx_1[df_spx_1.expiry_yyyymmdd==first_2_expiries[1]]\n",
    "    df_spx_exp2_with_all_fields = get_valid_series_from_csv_file_df(df_spx_exp2)\n",
    "\n",
    "    Tnear = df_spx_exp1_with_all_fields.iloc[0].dte_pct\n",
    "    Tfar = df_spx_exp2_with_all_fields.iloc[0].dte_pct\n",
    "    T30 = 30/365\n",
    "    w = (Tfar-T30)/(Tfar-Tnear)\n",
    "    skew_near = create_skew(df_spx_exp1_with_all_fields)\n",
    "    skew_far = create_skew(df_spx_exp2_with_all_fields)\n",
    "    final_skew = w*skew_near + (1-w) * skew_far\n",
    "    actual_skew = df_skew[df_skew.yyyymmdd==d].iloc[0].SKEW\n",
    "    print(d,actual_skew,final_skew,skew_near,skew_far,w,first_2_expiries[0],first_2_expiries[1])    \n",
    "\n",
    "    dict_df_exp_pair[d] = {\n",
    "        'df_spx_1':df_spx_exp1_with_all_fields,\n",
    "                           'df_spx_2':df_spx_exp2_with_all_fields,\n",
    "                           'skew_near':skew_near,\n",
    "                           'skew_far':skew_far,\n",
    "                           'final_skew':final_skew\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use ES contract history from sec_db database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'CLZ18'\n",
    "d = 20180801\n",
    "sql = f'''\n",
    "select * from sec_schema.options_table ot\n",
    "where ot.settle_date>={d} \n",
    "and ot.symbol='{s}'\n",
    ";\n",
    "'''\n",
    "df_options = pga.get_sql(sql)\n",
    "\n",
    "\n",
    "sql = f'''\n",
    "select * from sec_schema.underlying_table ft \n",
    "where ft.settle_date='{d}' \n",
    "and ft.symbol='{s}'\n",
    ";\n",
    "'''\n",
    "df_futures = pga.get_sql(sql)\n",
    "df_options['forward_price'] = df_futures.iloc[0].close\n",
    "df_options['trade_date_yyyymmdd'] = df_options.settle_date\n",
    "\n",
    "print(df_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create date math functions to get options/futures expiry dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = f'./opvoct15/opv10015.csv'\n",
    "import io\n",
    "def _df_from_text(text_path):\n",
    "    lines = open(text_path,'r').read()\n",
    "    options_header = 'contract,month_year,strike_right,date,open,high,low,close,volume,open_interest'\n",
    "    lines2 = options_header + '\\n'+ lines\n",
    "    lines3 = lines2.split('\\n')\n",
    "    s2 = io.StringIO()\n",
    "    for l in lines3:\n",
    "        s2.write(l+'\\n')\n",
    "    s2.seek(0)\n",
    "    df = pd.read_csv(s2)\n",
    "    return df\n",
    "df_tt = _df_from_text(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sorted(df_tt.contract.unique()) if s[0]=='E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tt[df_tt.contract.str.contains('ES')].month_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\" \".join(sorted(list(set([s[:4] for s in df_tt[df_tt.contract.str.contains('ES')].strike_right.unique()]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "\n",
    "# from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday, nearest_workday, \\\n",
    "#     USMartinLutherKingJr, USPresidentsDay, GoodFriday, USMemorialDay, \\\n",
    "#     USLaborDay, USThanksgivingDay\n",
    "\n",
    "\n",
    "# class USTradingCalendar(AbstractHolidayCalendar):\n",
    "#     rules = [\n",
    "#         Holiday('NewYearsDay', month=1, day=1, observance=nearest_workday),\n",
    "#         USMartinLutherKingJr,\n",
    "#         USPresidentsDay,\n",
    "#         GoodFriday,\n",
    "#         USMemorialDay,\n",
    "#         Holiday('USIndependenceDay', month=7, day=4, observance=nearest_workday),\n",
    "#         USLaborDay,\n",
    "#         USThanksgivingDay,\n",
    "#         Holiday('Christmas', month=12, day=25, observance=nearest_workday)\n",
    "#     ]\n",
    "\n",
    "\n",
    "# def get_trading_close_holidays(year):\n",
    "#     inst = USTradingCalendar()\n",
    "\n",
    "#     return inst.holidays(dt.datetime(year-1, 12, 31), dt.datetime(year, 12, 31))\n",
    "\n",
    "\n",
    "# print(get_trading_close_holidays(2014)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ESX15 and ESZ15 options, ESZ15 underlying to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'ESV15'\n",
    "d = 20151001\n",
    "sql = f'''\n",
    "select * from sec_schema.options_table ot\n",
    "where ot.symbol='{s}' and settle_date={d}\n",
    ";\n",
    "'''\n",
    "df_options = pga.get_sql(sql)\n",
    "\n",
    "f = 'ESZ15'\n",
    "sql = f'''\n",
    "select * from sec_schema.underlying_table ot\n",
    "where ot.symbol='{f}'  and settle_date={d}\n",
    ";\n",
    "'''\n",
    "df_futures = pga.get_sql(sql)\n",
    "atm = df_futures.iloc[0].close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = df_options[(df_options.pc.str.lower()=='c')][['settle_date','strike','close','pc']].sort_values('strike')\n",
    "dfc = dfc[dfc.strike >= atm]\n",
    "dfp = df_options[(df_options.pc.str.lower()=='p')][['settle_date','strike','close','pc']].sort_values('strike')\n",
    "dfp = dfp[dfp.strike < atm]\n",
    "dfb = dfc.append(dfp).sort_values(['pc','strike'])\n",
    "dfb.pc = dfb.pc.str.lower()\n",
    "dfb = dfb.rename(columns={'pc':'cp','settle_date':'trade_date_yyyymmdd'})\n",
    "dfb = dfb[dfb.close >= 1 ]\n",
    "dfb['expiry_yyyymmdd']  = get_expiry('ESV15')\n",
    "dfb.strike.min(),dfb.strike.max(),len(dfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create SKEW from ESV15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_20151001 = get_rate(1,dt_from_yyyymmdd(20151001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_fut_mon = {'F':'H','G':'H','H':'H','J':'M','K':'M','M':'M','N':'U','Q':'U','U':'U','V':'Z','X':'Z','Z':'Z'}\n",
    "def get_valid_series_from_barchartacs(symbol,trade_date_yyyymmdd,\n",
    "                                      interest_rate=None,deltak=DELTA_K):\n",
    "    threshold_bid = DICT_THRESHOLD_BIDS[symbol[:2]]\n",
    "#     print(symbol,trade_date_yyyymmdd)\n",
    "    ir = interest_rate \n",
    "    if ir is None:\n",
    "        ir = get_rate(1,dt_from_yyyymmdd(trade_date_yyyymmdd))\n",
    "        \n",
    "#     # ****** Step 01: get futures data from sql\n",
    "    fm = dict_fut_mon[symbol[2]]\n",
    "    futures_symbol = symbol[0:2] + fm + symbol[3:]\n",
    "    sql = f'''\n",
    "    select * from sec_schema.underlying_table ot\n",
    "    where ot.symbol='{futures_symbol}'  and settle_date={trade_date_yyyymmdd}\n",
    "    ;\n",
    "    '''\n",
    "    df_futures = pga.get_sql(sql)\n",
    "    forward_price = df_futures.iloc[0].close\n",
    "\n",
    "#     # ****** Step 02: get options data from sql\n",
    "    sql = f'''\n",
    "    select * from sec_schema.options_table ot\n",
    "    where ot.symbol='{symbol}'  and settle_date={trade_date_yyyymmdd}\n",
    "    ;\n",
    "    '''\n",
    "    df_options = pga.get_sql(sql)\n",
    "    dfc = df_options[(df_options.pc.str.lower()=='c')][['settle_date','strike','close','pc']].sort_values('strike')\n",
    "    dfc = dfc[dfc.strike >= forward_price]\n",
    "    dfp = df_options[(df_options.pc.str.lower()=='p')][['settle_date','strike','close','pc']].sort_values('strike')\n",
    "    dfp = dfp[dfp.strike < forward_price]\n",
    "    atm_strike = dfc[dfc.strike == dfc.strike.min()].iloc[0].strike\n",
    "    \n",
    "    # ******  Step 03: merge puts and alls into one dataframe\n",
    "    dfb = dfc.append(dfp).sort_values(['pc','strike'])    \n",
    "    dfb.pc = dfb.pc.str.lower()\n",
    "    dfb = dfb.rename(columns={'pc':'cp','settle_date':'trade_date_yyyymmdd','close':'mid'})\n",
    "    dfb = dfb[dfb.mid >= threshold_bid ]\n",
    "    exp_dt  = get_expiry(symbol)\n",
    "    expiry_yyyymmdd = int(exp_dt.year)*100*100 + int(exp_dt.month)*100 + int(exp_dt.day)\n",
    "    dfb['expiry_yyyymmdd'] = expiry_yyyymmdd\n",
    "    df_ret = dfb.copy()\n",
    "    df_ret['trade_date_yyyymmdd'] = trade_date_yyyymmdd\n",
    "    df_ret['forward_price'] = forward_price\n",
    "    \n",
    "    df_ret = df_ret.sort_values(['cp','strike'])\n",
    "    df_ret.index = range(len(df_ret))\n",
    "\n",
    "    # ******  Step 04: Add m dte_pct, ert  \n",
    "    dte_pct = get_dte_pct(trade_date_yyyymmdd,expiry_yyyymmdd)\n",
    "    df_ret['dte_pct'] = dte_pct\n",
    "    ert = np.exp(dte_pct * ir)\n",
    "    df_ret['ert'] = ert\n",
    "    \n",
    "    df_ret['k_over_fp'] = df_ret.strike / forward_price\n",
    "    df_ret['deltak'] = deltak\n",
    "    \n",
    "    # ****** Step 05: create p1,p2,p3, e1,e2,e3 unit values\n",
    "    df_ret['p1']= df_ret.apply(lambda r: r.deltak / r.strike**2 * r.mid,axis=1)\n",
    "    df_ret['p2'] = df_ret.apply(lambda r: 2 * r.p1 *(1-np.log(r.k_over_fp)),axis=1)\n",
    "    df_ret['p3'] = df_ret.apply(lambda r: 3 * r.p1 * (2*np.log(r.k_over_fp) - np.log(r.k_over_fp)**2),axis=1)\n",
    "    e1 = -(1+np.log(forward_price/atm_strike) - forward_price/atm_strike)\n",
    "    e2 = 2 * np.log(atm_strike/forward_price) * (forward_price/atm_strike - 1) + 1/2 * np.log(atm_strike/forward_price)**2\n",
    "    e3 = 3 * np.log(atm_strike/forward_price)**2 * (1/3 * np.log(atm_strike/forward_price) - 1 + forward_price/atm_strike)\n",
    "    df_ret['e1'] = e1\n",
    "    df_ret['e2'] = e2\n",
    "    df_ret['e3'] = e3\n",
    "    return df_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valid_series_from_barchartacs('NGM19',20190401,interest_rate=.02,deltak=.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through a set of days and calculate skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trade_date_yyyymmdd_beg = 20180701\n",
    "trade_date_yyyymmdd_end = 20180810\n",
    "df_rates = get_rate_df(1,trade_date_yyyymmdd_beg,trade_date_yyyymmdd_end)\n",
    "symbol='ESU18'\n",
    "futures_symbol = 'ES' + dict_fut_mon[symbol[2]] + symbol[3:]\n",
    "sql = f'''\n",
    "select * from sec_schema.underlying_table ot\n",
    "where ot.symbol='{futures_symbol}'  and settle_date>={trade_date_yyyymmdd_beg} and settle_date <= {trade_date_yyyymmdd_end}\n",
    ";\n",
    "'''\n",
    "trade_dates_yyyymmdd = pga.get_sql(sql).settle_date.values\n",
    "dates = []\n",
    "actual_skews = []\n",
    "final_skews  = []\n",
    "dict_df_exp_pair = {}\n",
    "for d in trade_dates_yyyymmdd:\n",
    "    ir = df_rates[df_rates.date_yyyymmdd==d].iloc[0].fixed_rate\n",
    "    dfes = get_valid_series_from_barchartacs(symbol,d,interest_rate=ir,deltak=5)\n",
    "    final_skew = create_skew(dfes)\n",
    "    actual_skew = df_skew[df_skew.yyyymmdd==d].iloc[0].SKEW\n",
    "    print(d,actual_skew,final_skew) \n",
    "    dates.append(d)\n",
    "    actual_skews.append(actual_skew)\n",
    "    final_skews.append(final_skew)\n",
    "    dict_df_exp_pair[d] = {\n",
    "        'df_spx_1':dfes.copy(),\n",
    "                           'final_skew':final_skew\n",
    "    }\n",
    "df_pga_skew = pd.DataFrame({'date':dates,'actual_skew':actual_skews,'final_skew':final_skews})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pga_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(cvt.plotly_plot(df_pga_skew,'date',plot_title='skew'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skew_df(symbol,beg_yyyymmdd, end_yyyymmdd,deltak=5):\n",
    "    trade_date_yyyymmdd_beg = beg_yyyymmdd\n",
    "    trade_date_yyyymmdd_end = end_yyyymmdd\n",
    "    df_rates = get_rate_df(1,trade_date_yyyymmdd_beg,trade_date_yyyymmdd_end)\n",
    "    futures_symbol = symbol[:(len(symbol)-3)] + dict_fut_mon[symbol[2]] + symbol[3:]\n",
    "    sql = f'''\n",
    "    select * from sec_schema.underlying_table ot\n",
    "    where ot.symbol='{futures_symbol}'  and settle_date>={trade_date_yyyymmdd_beg} and settle_date <= {trade_date_yyyymmdd_end}\n",
    "    ;\n",
    "    '''\n",
    "    trade_dates_yyyymmdd = pga.get_sql(sql).settle_date.values\n",
    "    dates = []\n",
    "    final_skews  = []\n",
    "    dict_df_exp_pair = {}\n",
    "    for d in trade_dates_yyyymmdd:\n",
    "        ir = df_rates[df_rates.date_yyyymmdd==d].iloc[0].fixed_rate\n",
    "        dfes = get_valid_series_from_barchartacs(symbol,d,interest_rate=ir,deltak=deltak)\n",
    "        final_skew = create_skew(dfes)\n",
    "        dates.append(d)\n",
    "        final_skews.append(final_skew)\n",
    "        dict_df_exp_pair[d] = {\n",
    "            'df_spx_1':dfes.copy(),\n",
    "                               'final_skew':final_skew\n",
    "        }\n",
    "    df_pga_skew = pd.DataFrame({'date':dates,'final_skew':final_skews})    \n",
    "    return df_pga_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valid_series_from_barchartacs('CLF20',20191001,interest_rate=get_rate(1,datetime.datetime(2019,10,1)),deltak=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 'NGM19'\n",
    "dfs = create_skew_df(ss,20190321,20190422,deltak=.1)\n",
    "iplot(cvt.plotly_plot(dfs,'date',plot_title=f'{ss} skew'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dash app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define cell styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTS_TO_DISPLAY_DICT = {'names':['E-Mini SP','Nymex Crude','Ice Brent','NYMEX Natural Gas'], \n",
    "                             'symbols':['ES','CL','CB','NG']\n",
    "}                             \n",
    "\n",
    "# Create css styles for some parts of the display\n",
    "\n",
    "STYLE_TITLE={\n",
    "    'line-height': '20px',\n",
    "    'textAlign': 'center',\n",
    "    'background-color':'#47bacc',\n",
    "    'color':'#FFFFF9',\n",
    "    'vertical-align':'middle',\n",
    "} \n",
    "\n",
    "STYLE_UPGRID = STYLE_TITLE.copy()\n",
    "STYLE_UPGRID['background-color'] = '#EAEDED'\n",
    "STYLE_UPGRID['line-height'] = '10px'\n",
    "STYLE_UPGRID['color'] = '#21618C'\n",
    "STYLE_UPGRID['height'] = '50px'\n",
    "\n",
    "ALL_SYMBOL_SQL = 'select distinct symbol from sec_schema.options_table;'\n",
    "ALL_SYMBOLS = pga.get_sql(ALL_SYMBOL_SQL).symbol.values\n",
    "ALL_PRODUCTS = sorted(list(set([s[:2] for s in ALL_SYMBOLS])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_years_per_product(product):\n",
    "    global ALL_SYMBOLS\n",
    "    return sorted(list(set([s[3:] for s in ALL_SYMBOLS if s[:2] == product])))\n",
    "def get_all_monthcodes_per_product(product,year):\n",
    "    global ALL_SYMBOLS\n",
    "    yy = str(year)[-2:]\n",
    "    return sorted(list(set([s[2] for s in ALL_SYMBOLS if (s[:2] == product) & (s[-2:]==yy)])))\n",
    "def get_dates_per_symbol(symbol):\n",
    "    sql_dates = f'''\n",
    "    select min(settle_date) min_date, max(settle_date) max_date \n",
    "    from sec_schema.options_table \n",
    "    where symbol='{symbol}'; \n",
    "    '''\n",
    "    df_dates_per_symbol = pga.get_sql(sql_dates)\n",
    "    min_date_yyyymmdd = int(df_dates_per_symbol.iloc[0].min_date)\n",
    "    max_date_yyyymmdd = int(df_dates_per_symbol.iloc[0].max_date)\n",
    "    # subtract 11 days from max_date_yyyymmdd\n",
    "    max_date_yyyymmdd = yyyymmdd_from_dt(dt_from_yyyymmdd(max_date_yyyymmdd) - datetime.timedelta(11))\n",
    "    return [min_date_yyyymmdd,max_date_yyyymmdd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dates_per_symbol('CLM19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(2011,2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT_PROD = 'CL'\n",
    "# DEFAULT_YEAR = 2020\n",
    "# # Step 1: create a title at the top\n",
    "# title_div = html.Div([html.H3('Commodity Options SKEW INDEX Analysis')],style=STYLE_TITLE)\n",
    "\n",
    "# # Step 2: create a grid that includes an explanation, and 2 dropdowns\n",
    "# #    Step 2.1: create the information h3\n",
    "# m = html.H3(\"From the dropdown buttons to the right, select a Commodity and/or a Year\",style={'height':'1px'})\n",
    "# info_div = dgrid.GridItem(m,html_id='explain')\n",
    "# select_commod_div  = dgrid.DropDownDiv('commod_dropdown', \n",
    "#                         CONTRACTS_TO_DISPLAY_DICT['names'], \n",
    "#                          CONTRACTS_TO_DISPLAY_DICT['symbols'],style=STYLE_UPGRID,\n",
    "#                         transformer_method=lambda data: data#_transform_commod_selection\n",
    "#                          )\n",
    "# init_whole_years = [str(i) for i in list(range(2011,2021))]\n",
    "# init_yy = [str(i)[-2:] for i in init_whole_years]\n",
    "# select_year_div =  dgrid.DropDownDiv('year_dropdown',                         \n",
    "#                         init_whole_years,init_yy,\n",
    "#                         style=STYLE_UPGRID,default_initial_index=len(init_whole_years)-1)\n",
    "\n",
    "\n",
    "\n",
    "# init_months = [s for s in 'FGHJKMNQUVXZ']\n",
    "# select_month_div =  dgrid.DropDownDiv('month_dropdown',                         \n",
    "#                         init_months,init_months,\n",
    "#                         style=STYLE_UPGRID,default_initial_index=len(init_months)-1)\n",
    "\n",
    "# dropdown_grid = dgrid.create_grid([info_div,select_commod_div,select_year_div,select_month_div],num_columns=4,column_width_percents=[55,14.95,14.95,14.95])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define main grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_symbol_to_show():\n",
    "#     prod = select_commod_div.current_value\n",
    "#     month = select_month_div.current_value\n",
    "#     yy = select_year_div.current_value\n",
    "#     sym = prod+month+yy\n",
    "#     print(f'get_symbol_to_show: {sym}')\n",
    "#     # get all dates for this sym\n",
    "#     beg_end_yyyymmdds = get_dates_per_symbol(sym)\n",
    "#     # get last date\n",
    "#     end_yyyymmdd = beg_end_yyyymmdds[1]\n",
    "#     # make first date 60 days back from last date\n",
    "#     dt_beg = dt_from_yyyymmdd(end_yyyymmdd) - datetime.timedelta(60)\n",
    "#     beg_yyyymmdd = yyyymmdd_from_dt(dt_beg)\n",
    "#     deltak = DICT_DELTAK[prod]\n",
    "#     dfs = create_skew_df(sym,beg_yyyymmdd,end_yyyymmdd,deltak=deltak)\n",
    "#     fig = cvt.plotly_plot(dfs,'date',plot_title=f'{sym} skew')\n",
    "#     gr = dgrid.GridGraph(fig.layout.title, fig.layout.title ,None,figure=fig,\n",
    "#             df_x_column='date')\n",
    "#     # combine the table and the graph into the main grid\n",
    "#     main_grid =  dgrid.create_grid([gr],num_columns=1)\n",
    "#     return main_grid\n",
    "\n",
    "# content_div = dgrid.ReactiveDiv('page_content',select_commod_div.output_tuple,\n",
    "# #                     input_transformer=lambda commod,data:main_grid,\n",
    "#                     input_transformer=lambda commod,data:get_symbol_to_show(),\n",
    "#                     dom_storage_dict=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = dash.Dash(url_base_pathname='/skew/')\n",
    "# main_div = html.Div(children=[title_div,dropdown_grid,content_div.html])\n",
    "\n",
    "# app.layout = html.Div(children=[main_div])\n",
    "\n",
    "# callback_components = [select_commod_div,select_year_div,select_month_div,content_div]\n",
    "# [c.callback(app) for c in callback_components]\n",
    "\n",
    "\n",
    "# # Step 5: run the server    \n",
    "# host = '127.0.0.1'\n",
    "# port = 8600\n",
    "# app.run_server(host=host,port=port)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dash App to server up SKEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../risktables'))\n",
    "sys.path.append(os.path.abspath('../../risktables/risktables'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risktables import dgrid_components as dgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dgc)\n",
    "# dgc.XyGraphComponent??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_monthcodes_per_product('ES',2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(sym):\n",
    "    global DICT_DELTAK\n",
    "    # get all dates for this sym\n",
    "    beg_end_yyyymmdds = get_dates_per_symbol(sym)\n",
    "    # get last date\n",
    "    end_yyyymmdd = beg_end_yyyymmdds[1]\n",
    "    # make first date 60 days back from last date\n",
    "    dt_beg = dt_from_yyyymmdd(end_yyyymmdd) - datetime.timedelta(60)\n",
    "    beg_yyyymmdd = yyyymmdd_from_dt(dt_beg)\n",
    "    prod = sym[:2]\n",
    "    deltak = DICT_DELTAK[prod]\n",
    "    dfs = create_skew_df(sym,beg_yyyymmdd,end_yyyymmdd,deltak=deltak)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = dgc.init_root_logger('logfile.log','WARN') \n",
    "\n",
    "top_div = html.Div([\n",
    "                    dgc.dcc.Markdown('''\n",
    "                    # Commodity Option SKEW Analysis\n",
    "                    Select a Commodity, Year and Monthcode below. The resulting data is derived from the CBOE SKEW formula outlined in the whitepaper: \n",
    "                    \n",
    "                    (https://www.cboe.com/micro/skew/documents/skewwhitepaperjan2011.pdf)\n",
    "                    '''\n",
    "                    ,style={'color':'white'})\n",
    "            ],\n",
    "            style=STYLE_TITLE,id='top_div')\n",
    "\n",
    "\n",
    "dropdown_instructions = dgc.DivComponent('dd_instructions',initial_children=['Select from the Product, Year and Month Dropdowns'])\n",
    "\n",
    "chained_dd_prods = dgc.ChainedDropDownDiv('chained_dd_prods',\n",
    "                initial_dropdown_labels=['Emini','WTI Crude','Brent Crude'],\n",
    "                initial_dropdown_values=['ES','CL','CB'])\n",
    "\n",
    "def _chained_years(inputs):\n",
    "    prod = inputs[1]\n",
    "    if prod is None or len(prod)<1:\n",
    "        return []\n",
    "    yys = get_all_years_per_product(prod)\n",
    "    choices = [{'label':str(2000 + int(yy)),'value':yy} for yy in yys]\n",
    "    return  choices\n",
    "\n",
    "    \n",
    "chained_dd_years = dgc.ChainedDropDownDiv('chained_dd_years',\n",
    "                dropdown_input_components=[chained_dd_prods],\n",
    "                choices_transformer_method=_chained_years,\n",
    "                placeholder=\"Select a year\")\n",
    "\n",
    "def _chained_months(inputs):\n",
    "    if inputs is None or len(inputs)<3:\n",
    "        return []\n",
    "    prod = inputs[1]\n",
    "    if prod is None or len(prod)<1:\n",
    "        return []\n",
    "    yy = inputs[2]\n",
    "    if yy is None or len(yy)<1:\n",
    "        return []\n",
    "    year = 2000 + int(yy)\n",
    "    mcs = get_all_monthcodes_per_product(prod,year)\n",
    "    choices = [{'label':mc ,'value':mc} for mc in mcs]\n",
    "    return  choices\n",
    "\n",
    "    \n",
    "chained_dd_months = dgc.ChainedDropDownDiv('chained_dd_months',\n",
    "                dropdown_input_components=[chained_dd_prods,chained_dd_years],\n",
    "                choices_transformer_method=_chained_months,\n",
    "                placeholder=\"Select a month code\")\n",
    "\n",
    "full_symbol_store_inputs = [\n",
    "    (chained_dd_prods.dropdown_id,'value'),\n",
    "    (chained_dd_years.dropdown_id,'value'),\n",
    "    (chained_dd_months.dropdown_id,'value'),    \n",
    "]\n",
    "\n",
    "def _create_full_symbol(inputs):\n",
    "    print(f'_create_full_symbol inputs {inputs}')\n",
    "    if inputs is None or len(inputs)<3 or inputs[0] is None or inputs[1] is None or inputs[2] is None:\n",
    "        return {}\n",
    "    prod = inputs[0]\n",
    "    yy = str(inputs[1])[-2:]\n",
    "    month = inputs[2]\n",
    "    full_symbol = prod+month+yy\n",
    "    full_symbol = full_symbol.upper()\n",
    "    print(f'full_symbol {full_symbol}')\n",
    "    dict_df = show_data(full_symbol).to_dict()\n",
    "    return {'full_symbol':full_symbol,'df':dict_df}\n",
    "    \n",
    "full_symbol_store = dgc.StoreComponent('symbol_store',full_symbol_store_inputs,\n",
    "                            create_data_dictionary_from_df_transformer=_create_full_symbol)\n",
    "\n",
    "def _symbol_from_store(inputs):\n",
    "    print(f'_symbol_from_store inputs: {inputs}')\n",
    "    if inputs is None or len(inputs)<1:\n",
    "        return ['']\n",
    "    sym_dict = inputs[0]\n",
    "    if sym_dict is None or len(sym_dict)<1:\n",
    "        return ['']\n",
    "    return [sym_dict['full_symbol']]\n",
    "\n",
    "full_symbol_div = dgc.DivComponent('full_symbol_div',input_component=full_symbol_store,\n",
    "                                  callback_input_transformer=_symbol_from_store)\n",
    "\n",
    "def transform_input_to_df(dict_df,key_of_df,columns_to_show=None):\n",
    "    df = None\n",
    "    dict_this_risk = None\n",
    "    if len(dict_df)>0:\n",
    "        dict_this_risk = dict_df[key_of_df]\n",
    "        df = dgc.make_df(dict_this_risk)\n",
    "        if columns_to_show is not None:\n",
    "            df = df[columns_to_show]\n",
    "    return df\n",
    "\n",
    "\n",
    "dash_graph = dgc.XyGraphComponent('dash_graph',full_symbol_store,'date',\n",
    "                title=\"Skew Graph\",plot_bars=False,\n",
    "                transform_input=lambda dict_df: transform_input_to_df(dict_df,'df'))\n",
    "\n",
    "dash_table = dgc.DashTableComponent('dash_table',None,input_component=full_symbol_store,\n",
    "                title=\"Skew Data\",\n",
    "                transform_input=lambda dict_df: transform_input_to_df(dict_df,'df'),\n",
    "                columns_to_round=[],digits_to_round=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_to_use = dash.Dash(url_base_pathname='/skew/')\n",
    "# app.layout = html.Div(children=[chained_dd.html])\n",
    "\n",
    "app_component_list = [top_div,dropdown_instructions,chained_dd_prods,\n",
    "                      chained_dd_years,chained_dd_months,full_symbol_store,full_symbol_div,dash_graph,dash_table]\n",
    "\n",
    "gtcl = ['1fr','4fr 1fr 1fr 1fr','0fr 1fr','1fr','1fr']\n",
    "app = dgc.make_app(app_component_list,\n",
    "                app=app_to_use,\n",
    "                grid_template_columns_list=gtcl)    \n",
    "\n",
    "\n",
    "# Step 5: run the server    \n",
    "host = '127.0.0.1'\n",
    "port = 8600\n",
    "app.run_server(host=host,port=port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
